{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICS WORKSHEET-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 to Q12 have only one correct answer. Choose the correct option to answer your question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) In hypothesis testing, type II error is represented by β and the power of the test is 1−β then β is:\n",
    "    \n",
    "a. The probability of rejecting H0 when H1 is true\n",
    "b. The probability of failing to reject H0 when H1 is true\n",
    "c. The probability of failing to reject H1 when H0 is true\n",
    "d. The probability of rejecting H0 when H1 is true\n",
    "\n",
    "--> b. The probability of failing to reject H0 when H1 is true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) In hypothesis testing, the hypothesis which is tentatively assumed to be true is called the\n",
    "\n",
    "a. correct hypothesis\n",
    "b. null hypothesis \n",
    "c. alternative hypothesis\n",
    "d. level of significance\n",
    "\n",
    "--> b. null hypothesis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) When the null hypothesis has been true, but the sample information has resulted in the rejection of the null, a \n",
    "_________ has been made\n",
    "\n",
    "a. level of significance\n",
    "b. Type II error\n",
    "c. critical value\n",
    "d. Type I error\n",
    "\n",
    "--> d. Type I error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) For finding the p-value when the population standard deviation is unknown, if it is reasonable to assume that the \n",
    "population is normal, we use\n",
    "\n",
    "a. the z distribution\n",
    "b. the t distribution with n - 1 degrees of freedom\n",
    "c. the t distribution with n + 1 degrees of freedom\n",
    "d. none of the above\n",
    "\n",
    "--> b. the t distribution with n - 1 degrees of freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) A Type II error is the error of\n",
    "\n",
    "a. accepting Ho when it is false\n",
    "b. accepting Ho when it is true\n",
    "c. rejecting Ho when it is false\n",
    "d. rejecting Ho when it is true\n",
    "\n",
    "--> a. accepting Ho when it is false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) A hypothesis test in which rejection of the null hypothesis occurs for values of the point estimator in either tail of \n",
    "the sampling distribution is called\n",
    "\n",
    "a. the null hypothesis\n",
    "b. the alternative hypothesis\n",
    "c. a one-tailed test\n",
    "d. a two-tailed test\n",
    "\n",
    "--> d. a two-tailed test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) In hypothesis testing, the level of significance is\n",
    "\n",
    "a. the probability of committing a Type II error\n",
    "b. the probability of committing a Type I error\n",
    "c. the probability of either a Type I or Type II, depending on the hypothesis to be tested\n",
    "d. none of the above\n",
    "\n",
    "--> b. the probability of committing a Type I error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) In hypothesis testing, b is\n",
    "\n",
    "a. the probability of committing a Type II error\n",
    "b. the probability of committing a Type I error\n",
    "c. the probability of either a Type I or Type II, depending on the hypothesis to be test\n",
    "d. none of the above\n",
    "\n",
    "--> a. the probability of committing a Type II error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) When testing the following hypotheses at an α level of significance\n",
    "H0: p = 0.7\n",
    "H1: p > 0.7\n",
    "The null hypothesis will be rejected if the test statistic Z is\n",
    "\n",
    "a. z > zα\n",
    "b. z < zα\n",
    "c. z < -z\n",
    "d. none of the above\n",
    "\n",
    "--> a. z > zα"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Which of the following does not need to be known in order to compute the P-value?\n",
    "\n",
    "a. knowledge of whether the test is one-tailed or two-tail\n",
    "b. the value of the test statistic\n",
    "c. the level of significance\n",
    "d. All of the above are needed\n",
    "\n",
    "--> c. the level of significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) The maximum probability of a Type I error that the decision maker will tolerate is called the\n",
    "\n",
    "a. level of significance\n",
    "b. critical value\n",
    "c. decision value\n",
    "d. probability value\n",
    "\n",
    "--> a. level of significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) For t distribution, increasing the sample size, the effect will be on\n",
    "\n",
    "a. Degrees of Freedom\n",
    "b. The t-ratio\n",
    "c. Standard Error of the Means\n",
    "d. All of the Above\n",
    "\n",
    "--> d. All of the Above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13 to Q15 are subjective answers type questions. Answers them in their own words briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) What is Anova in SPSS?\n",
    "\n",
    "--> Analysis of Variance, i.e. ANOVA in SPSS, is used for examining the differences in the mean values of the dependent variable associated with the effect of the controlled independent variables, after taking into account the influence of the uncontrolled independent variables. Essentially, ANOVA in SPSS is used as the test of means for two or more populations.\n",
    "\n",
    "ANOVA in SPSS must have a dependent variable which should be metric (measured using an interval or ratio scale). ANOVA in SPSS must also have one or more independent variables, which should be categorical in nature. In ANOVA in SPSS, categorical independent variables are called factors. A particular combination of factor levels, or categories, is called a treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) What are the assumptions of Anova?\n",
    "\n",
    "--> To use the ANOVA test we made the following assumptions:\n",
    "\n",
    "Each group sample is drawn from a normally distributed population\n",
    "\n",
    "All populations have a common variance\n",
    "\n",
    "All samples are drawn independently of each other\n",
    "\n",
    "Within each sample, the observations are sampled randomly and independently of each other\n",
    "\n",
    "Factor effects are additive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) What is the difference between one way Anova and two way Anova?\n",
    "\n",
    "--> A hypothesis test that enables us to test the equality of three or more means simultaneously using variance is called One way ANOVA. A statistical technique in which the interrelationship between factors, influencing variable can be studied for effective decision making, is called Two-way ANOVA.\n",
    "\n",
    "There is only one factor or independent variable in one way ANOVA whereas in the case of two-way ANOVA there are two independent variables.\n",
    "\n",
    "One-way ANOVA compares three or more levels (conditions) of one factor. On the other hand, two-way ANOVA compares the effect of multiple levels of two factors.\n",
    "\n",
    "In one-way ANOVA, the number of observations need not be same in each group whereas it should be same in the case of two-way ANOVA.\n",
    "\n",
    "One-way ANOVA need to satisfy only two principles of design of experiments, i.e. replication and randomization. As opposed to Two-way ANOVA, which meets all three principles of design of experiments which are replication, randomization, and local control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTHON – WORKSHEET 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 to Q8 have only one correct answer. Choose the correct option to answer your question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Which of the following operators is used to calculate remainder in a division?\n",
    "\n",
    "A) # B) &\n",
    "C) % D) $\n",
    "\n",
    "--> C) %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) In python 2//3 is equal to?\n",
    "\n",
    "A) 0.666 B) 0\n",
    "C) 1 D) 0.67\n",
    "\n",
    "--> B) 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) In python, 6<<2 is equal to?\n",
    "A) 36 B) 10\n",
    "C) 24 D) 45\n",
    "\n",
    "--> C) 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) In python, 6&2 will give which of the following as output?\n",
    "\n",
    "A) 2 B) True\n",
    "C) False D) 0\n",
    "\n",
    "--> A) 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) In python, 6|2 will give which of the following as output?\n",
    "A) 2 B) 4\n",
    "C) 0 D) 6\n",
    "\n",
    "--> D) 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) What does the finally keyword denotes in python?\n",
    "\n",
    "A) It is used to mark the end of the code\n",
    "B) It encloses the lines of code which will be executed if any error occurs while executing the lines of code in \n",
    "the try block.\n",
    "C) the finally block will be executed no matter if the try block raises an error or not.\n",
    "D) None of the above\n",
    "\n",
    "--> C) the finally block will be executed no matter if the try block raises an error or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) What does raise keyword is used for in python?\n",
    "\n",
    "A) It is used to raise an exception. B) It is used to define lambda function\n",
    "C) it's not a keyword in python. D) None of the above\n",
    "\n",
    "--> A) It is used to raise an exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Which of the following is a common use case of yield keyword in python?\n",
    "\n",
    "A) in defining an iterator B) while defining a lambda function\n",
    "C) in defining a generator D) in for loop.\n",
    "\n",
    "--> C) in defining a generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9 and Q10 have multiple correct answers. Choose all the correct options to answer your question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Which of the following are the valid variable names?\n",
    "\n",
    "A) _abc B) 1abc\n",
    "C) abc2 D) None of the above\n",
    "\n",
    "--> A) _abc\n",
    "\n",
    "B) 1abc\n",
    "\n",
    "C) abc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Which of the following are the keywords in python?\n",
    "\n",
    "A) yield B) raise\n",
    "C) look-in D) all of the above\n",
    "\n",
    "--> A) yield\n",
    "\n",
    "B) raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11 to Q15 are programming questions. Answer them in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a number: 7\n",
      "The factorial of 7 is 5040\n"
     ]
    }
   ],
   "source": [
    "#11) Write a python program to find the factorial of a number.\n",
    "\n",
    "# To take input from the user\n",
    "num = int(input(\"Enter a number: \"))\n",
    "\n",
    "factorial = 1\n",
    "\n",
    "# check if the number is negative, positive or zero\n",
    "if num < 0:\n",
    "   print(\"Sorry, factorial does not exist for negative numbers\")\n",
    "elif num == 0:\n",
    "   print(\"The factorial of 0 is 1\")\n",
    "else:\n",
    "   for i in range(1,num + 1):\n",
    "       factorial = factorial*i\n",
    "   print(\"The factorial of\",num,\"is\",factorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter any number : 3\n",
      "3 is a PRIME number\n"
     ]
    }
   ],
   "source": [
    "#12) Write a python program to find whether a number is prime or composite.\n",
    "\n",
    "num = int(input(\"Enter any number : \"))\n",
    "if num > 1:\n",
    "    for i in range(2, num):\n",
    "        if (num % i) == 0:\n",
    "            print(num, \"is NOT a prime number\")\n",
    "            break\n",
    "    else:\n",
    "        print(num, \"is a PRIME number\")\n",
    "elif num == 0 or 1:\n",
    "    print(num, \"is a neither prime NOR composite number\")\n",
    "else:\n",
    "    print(num, \"is NOT a prime number it is a COMPOSITE number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter any string :racecar\n",
      "The string is a palindrome.\n"
     ]
    }
   ],
   "source": [
    "#13) Write a python program to check whether a given string is palindrome or not.\n",
    "\n",
    "my_str = str(input(\"Enter any string :\"))\n",
    "\n",
    "# make it suitable for caseless comparison\n",
    "my_str = my_str.casefold()\n",
    "\n",
    "# reverse the string\n",
    "rev_str = reversed(my_str)\n",
    "\n",
    "# check if the string is equal to its reverse\n",
    "if list(my_str) == list(rev_str):\n",
    "   print(\"The string is a palindrome.\")\n",
    "else:\n",
    "   print(\"The string is not a palindrome.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypotenuse = 5.0\n",
      "Adjacent = 4.0\n",
      "Opposite = 3.0\n",
      "You know the answer!\n"
     ]
    }
   ],
   "source": [
    "#14) Write a Python program to get the third side of right-angled triangle from two given sides.\n",
    "\n",
    "def pythagoras(opposite_side,adjacent_side,hypotenuse):\n",
    "        if opposite_side == str(\"x\"):\n",
    "            return (\"Opposite = \" + str(((hypotenuse**2) - (adjacent_side**2))**0.5))\n",
    "        elif adjacent_side == str(\"x\"):\n",
    "            return (\"Adjacent = \" + str(((hypotenuse**2) - (opposite_side**2))**0.5))\n",
    "        elif hypotenuse == str(\"x\"):\n",
    "            return (\"Hypotenuse = \" + str(((opposite_side**2) + (adjacent_side**2))**0.5))\n",
    "        else:\n",
    "            return \"You know the answer!\"\n",
    "\n",
    "print(pythagoras(3,4,'x'))\n",
    "print(pythagoras(3,'x',5))\n",
    "print(pythagoras('x',4,5))\n",
    "print(pythagoras(3,4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of all characters in WorkWorkWork is :\n",
      " {'W': 3, 'o': 3, 'r': 3, 'k': 3}\n"
     ]
    }
   ],
   "source": [
    "#15) Write a python program to print the frequency of each of the characters present in a given string.\n",
    "\n",
    "# initializing string \n",
    "test_str = \"WorkWorkWork\"\n",
    "  \n",
    "# using naive method to get count of each element in string \n",
    "all_freq = {}\n",
    "  \n",
    "for i in test_str:\n",
    "    if i in all_freq:\n",
    "        all_freq[i] += 1\n",
    "    else:\n",
    "        all_freq[i] = 1\n",
    "  \n",
    "# printing result \n",
    "print (\"Count of all characters in WorkWorkWork is :\\n \"\n",
    "                                        +  str(all_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Q1 to Q7, only one option is correct, Choose the correct option:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What is the advantage of hierarchical clustering over K-means clustering?\n",
    "\n",
    "A) Hierarchical clustering is computationally less expensive\n",
    "B) In hierarchical clustering you don’t need to assign number of clusters in beginning\n",
    "C) Both are equally proficient D) None of these\n",
    "\n",
    "--> D) None of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Which of the following hyper parameter(s), when increased may cause random forest to over fit the \n",
    "data?\n",
    "\n",
    "A) max_depth B) n_estimators \n",
    "C) min_samples_leaf D) min_samples_splits\n",
    "\n",
    "--> A) max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Which of the following is the least preferable resampling method in handling imbalance datasets?\n",
    "\n",
    "A) SMOTE B) RandomOverSampler\n",
    "C) RandomUnderSampler D) ADASYN\n",
    "\n",
    "--> C) RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Which of the following statements is/are true about “Type-1” and “Type-2” errors?\n",
    "\n",
    "1. Type1 is known as false positive and Type2 is known as false negative.\n",
    "2. Type1 is known as false negative and Type2 is known as false positive.\n",
    "3. Type1 error occurs when we reject a null hypothesis when it is actually true.\n",
    "\n",
    "A) 1 and 2 B) 1 only\n",
    "C) 1 and 3 D) 2 and 3\n",
    "\n",
    "--> D) 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Arrange the steps of k-means algorithm in the order in which they occur:\n",
    "\n",
    "1. Randomly selecting the cluster centroids\n",
    "2. Updating the cluster centroids iteratively\n",
    "3. Assigning the cluster points to their nearest center\n",
    "\n",
    "A) 3-1-2 B) 2-1-3\n",
    "C) 3-2-1 D) 1-3-2\n",
    "\n",
    "--> D) 1-3-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Which of the following algorithms is not advisable to use when you have limited CPU resources and \n",
    "time, and when the data set is relatively large?\n",
    "\n",
    "A) Decision Trees B) Support Vector Machines\n",
    "C) K-Nearest Neighbors D) Logistic Regression\n",
    "\n",
    "--> B) Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) What is the main difference between CART (Classification and Regression Trees) and CHAID (Chi \n",
    "Square Automatic Interaction Detection) Trees?\n",
    "\n",
    "A) CART is used for classification, and CHAID is used for regression.\n",
    "B) CART can create multiway trees (more than two children for a node), and CHAID can only create \n",
    "binary trees (a maximum of two children for a node).\n",
    "C) CART can only create binary trees (a maximum of two children for a node), and CHAID can create \n",
    "multiway trees (more than two children for a node)\n",
    "D) None of the above\n",
    "\n",
    "--> C) CART can only create binary trees (a maximum of two children for a node), and CHAID can create \n",
    "multiway trees (more than two children for a node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Q8 to Q10, more than one options are correct, Choose all the correct options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) In Ridge and Lasso regularization if you take a large value of regularization constant(lambda), which \n",
    "of the following things may occur?\n",
    "\n",
    "A) Ridge will lead to some of the coefficients to be very close to 0\n",
    "B) Lasso will lead to some of the coefficients to be very close to 0\n",
    "C) Ridge will cause some of the coefficients to become 0\n",
    "D) Lasso will cause some of the coefficients to become 0.\n",
    "\n",
    "--> A) Ridge will lead to some of the coefficients to be very close to 0\n",
    "\n",
    "D) Lasso will cause some of the coefficients to become 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Which of the following methods can be used to treat two multi-collinear features?\n",
    "A) remove both features from the dataset\n",
    "B) remove only one of the features \n",
    "C) Use ridge regularization D) use Lasso regularization\n",
    "\n",
    "--> B) remove only one of the features\n",
    "\n",
    "D) use Lasso regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) After using linear regression, we find that the bias is very low, while the variance is very high. What \n",
    "are the possible reasons for this?\n",
    "\n",
    "A) Overfitting B) Multicollinearity\n",
    "C) Underfitting D) Outliers\n",
    "\n",
    "--> A) Overfitting\n",
    "\n",
    "B) Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10 to Q15 are subjective answer type questions, Answer them briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) In which situation One-hot encoding must be avoided? Which encoding technique can be used in \n",
    "such a case?\n",
    "\n",
    "--> The disadvantage of one hot encoding is that for high cardinality, the feature space can really blow up quickly and you start fighting with the curse of dimensionality.\n",
    "\n",
    "In such case we can use label encoding technique to encode the categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) In case of data imbalance problem in classification, what techniques can be used to balance the \n",
    "dataset? Explain them briefly.\n",
    "\n",
    "--> There has been two different approaches to addressing imbalanced data: algorithm-level and data-level approach.\n",
    "\n",
    "Algorithm approach: As mentioned above, ML algorithms penalize False Positives and False Negatives equally. A way to counter that is to modify the algorithm itself to boost predictive performance on minority class. This can be executed through either recognition-based learning or cost-sensitive learning.\n",
    "\n",
    "Data approach: This consists of re-sampling the data in order to mitigate the effect caused by class imbalance. The data approach has gained popular acceptance among practitioners as it is more flexible and allows for the use of latest algorithms. The two most common techniques are over-sampling and under-sampling.\n",
    "\n",
    "Over sampling: Over-sampling increases the number of minority class members in the training set. The advantage of over-sampling is that no information from the original training set is lost, as all observations from the minority and majority classes are kept. On the other hand, it is prone to overfitting.\n",
    "\n",
    "Under sampling: Under-sampling, on contrary to over-sampling, aims to reduce the number of majority samples to balance the class distribution. Since it is removing observations from the original data set, it might discard useful information.\n",
    "\n",
    "EditedNearestNeighbours under-sampling technique (E2_ENN): The ENN method was proposed by Wilson (1972), in which a majority instance is removed if its class label does not agree with its K nearest neighbors. The ENN method tends to omit the noisy and borderline instances, which will therefore enhance the accuracy of decision boundary.\n",
    "\n",
    "NearMiss 3 under-sampling technique (E3_NM): NearMiss-3 belongs to the NearMiss family, which conducts under-sampling on the majority class according to their distance. NearMiss-3 in particular removes majority samples with the largest distance from minority samples’ K nearest neighbors.\n",
    "\n",
    "SMOTE over-sampling technique (E4_SMT): SMOTE first considers the K nearest neighbors of the minority instances. It then constructs feature space vectors between these K neighbors, generating new synthetic data points on the lines.\n",
    "\n",
    "ADASYN over-sampling technique (E5_ADS): Very similar to SMOTE, ADYSYN also creates synthetic data points with feature space vectors. However, for the new data points to be realistic, ADYSYN adds a small error to the data points to allow for some variance. This is because observations are not perfectly correlated in real life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) What is the difference between SMOTE and ADASYN sampling techniques?\n",
    "\n",
    "--> The key difference between ADASYN and SMOTE is that the ADASYN uses a density distribution, as a criterion to automatically decide the number of synthetic samples that must be generated for each minority sample by adaptively changing the weights of the different minority samples to compensate for the skewed distributions. The SMOTE generates the same number of synthetic samples for each original minority sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) What is the purpose of using GridSearchCV? Is it preferable to use in case of large datasets? Why or \n",
    "why not?\n",
    "\n",
    "--> GridSearchCV tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method. Hence after using this function we get accuracy/loss for every combination of hyperparameters and we can choose the one with the best performance.\n",
    "\n",
    "One of the drawbacks of grid search is that when it comes to dimensionality, it suffers when evaluating the number of hyperparameters grows exponentially. However, there is no guarantee that the search will produce the perfect solution, as it usually finds one by aliasing around the right set.\n",
    "\n",
    "However we can use Random search instead,\n",
    "Random search is a technique where random combinations of the hyperparameters are used to find the best solution for the built model. It is similar to grid search, and yet it has proven to yield better results comparatively. The drawback of random search is that it yields high variance during computing. Since the selection of parameters is completely random; and since no intelligence is used to sample these combinations, luck plays its part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) List down some of the evaluation metric used to evaluate a regression model. Explain each of them \n",
    "in brief.\n",
    "\n",
    "--> There are 3 main metrics for model evaluation in regression:\n",
    "\n",
    "1) R Square/Adjusted R Square\n",
    "\n",
    "2) Mean Square Error(MSE)/Root Mean Square Error(RMSE)\n",
    "\n",
    "3) Mean Absolute Error(MAE)\n",
    "\n",
    "R Square/Adjusted R Square:-\n",
    "R Square measures how much of variability in dependent variable can be explained by the model. It is square of Correlation Coefficient(R) and that is why it is called R Square.\n",
    "\n",
    "R Square is calculated by the sum of squared of prediction error divided by the total sum of square which replace the calculated prediction with mean. R Square value is between 0 to 1 and bigger value indicates a better fit between prediction and actual value.\n",
    "\n",
    "R Square is a good measure to determine how well the model fits the dependent variables. However, it does not take into consideration of overfitting problem. If your regression model has many independent variables, because the model is too complicated, it may fit very well to the training data but performs badly for testing data. That is why Adjusted R Square is introduced because it will penalise additional independent variables added to the model and adjust the metric to prevent overfitting issue.\n",
    "\n",
    "Mean Square Error(MSE)/Root Mean Square Error(RMSE):-\n",
    "While R Square is a relative measure of how well the model fits dependent variables, Mean Square Error is an absolute measure of the goodness for the fit.\n",
    "\n",
    "MSE is calculated by the sum of square of prediction error which is real output minus predicted output and then divide by the number of data points. It gives you an absolute number on how much your predicted results deviate from the actual number. You cannot interpret much insights from one single result but it gives you an real number to compare against other model results and help you select the best regression model.\n",
    "\n",
    "Root Mean Square Error(RMSE) is the square root of MSE. It is used more commonly than MSE because firstly sometimes MSE value can be too big to compare easily. Secondly, MSE is calculated by the square of error, and thus square root brings it back to the same level of prediction error and make it easier for interpretation.\n",
    "\n",
    "Mean Absolute Error(MAE):-\n",
    "Mean Absolute Error(MAE) is similar to Mean Square Error(MSE). However, instead of the sum of square of error in MSE, MAE is taking the sum of absolute value of error.\n",
    "\n",
    "Compare to MSE or RMSE, MAE is a more direct representation of sum of error terms. MSE gives larger penalisation to big prediction error by square it while MAE treats all errors the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
